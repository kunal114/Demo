import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import RFE
from sklearn.base import BaseEstimator, TransformerMixin

class NullColumnDropper(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X.dropna(axis=1)

class DynamicFeatureSelector:
    def __init__(self, n_outputs):
        self.n_outputs = n_outputs
        self.models = [RandomForestClassifier(n_estimators=100, random_state=42) for _ in range(n_outputs)]
        self.feature_selectors = [RFE(estimator=RandomForestClassifier(n_estimators=10, random_state=42), n_features_to_select=1, step=1) for _ in range(n_outputs)]
        self.null_droppers = [NullColumnDropper() for _ in range(n_outputs)]
        self.selected_features = [None] * n_outputs

    def fit(self, X, y):
        for i in range(self.n_outputs):
            # Drop columns with null values for this specific record
            X_valid = self.null_droppers[i].fit_transform(X)
            
            # Perform feature selection
            self.feature_selectors[i].fit(X_valid, y.iloc[:, i])
            self.selected_features[i] = X_valid.columns[self.feature_selectors[i].support_].tolist()
            
            # Train the model on selected features
            self.models[i].fit(X_valid[self.selected_features[i]], y.iloc[:, i])

    def predict(self, X):
        predictions = []
        for i in range(self.n_outputs):
            # Drop columns with null values for this specific record
            X_valid = self.null_droppers[i].transform(X)
            
            # Predict using only the selected features
            pred = self.models[i].predict(X_valid[self.selected_features[i]])
            predictions.append(pred)
        
        return np.column_stack(predictions)

def preprocess_data(data):
    # Replace empty strings with NaN
    data = data.replace('', np.nan)
    
    # Encode categorical variables
    categorical_columns = data.select_dtypes(include=['object']).columns
    data = pd.get_dummies(data, columns=categorical_columns)
    
    return data

# Main execution
if __name__ == "__main__":
    # Load your data
    data = pd.read_csv("your_data.csv")
    
    # Preprocess the data
    processed_data = preprocess_data(data)
    
    # Separate features and targets
    X = processed_data.drop(['output1', 'output2', ..., 'outputN'], axis=1)
    y = processed_data[['output1', 'output2', ..., 'outputN']]
    
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Initialize and train the model
    model = DynamicFeatureSelector(n_outputs=y.shape[1])
    model.fit(X_train, y_train)
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Evaluate the model
    for i in range(y.shape[1]):
        accuracy = accuracy_score(y_test.iloc[:, i], y_pred[:, i])
        print(f"Accuracy for output {i+1}: {accuracy}")
        print(f"Selected features for output {i+1}: {model.selected_features[i]}")



id,feature1,feature2,feature3,feature4,feature5,categorical1,categorical2,output
1,10.5,20,30,,50,red,small,A
2,15.2,25,35,45,,blue,medium,B
3,,22,32,42,52,green,large,C
4,12.8,,,40,55,red,medium,A
5,18.3,28,38,48,58,blue,small,B
6,14.7,24,34,,54,green,large,D
7,11.9,21,31,41,,red,medium,C
8,,26,36,46,56,blue,small,A
9,13.6,23,,43,53,green,large,B
10,16.4,27,37,47,57,red,medium,D



class DynamicFeatureSelector:
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.feature_selector = RFE(estimator=RandomForestClassifier(n_estimators=10, random_state=42), n_features_to_select=1, step=1)
        self.null_dropper = NullColumnDropper()
        self.selected_features = None

    def fit(self, X, y):
        # Drop columns with null values for this specific record
        X_valid = self.null_dropper.fit_transform(X)
        
        # Perform feature selection
        self.feature_selector.fit(X_valid, y)
        self.selected_features = X_valid.columns[self.feature_selector.support_].tolist()
        
        # Train the model on selected features
        self.model.fit(X_valid[self.selected_features], y)

    def predict(self, X):
        # Drop columns with null values for this specific record
        X_valid = self.null_dropper.transform(X)
        
        # Predict using only the selected features
        return self.model.predict(X_valid[self.selected_features])

# Main execution
if __name__ == "__main__":
    # Load your data
    data = pd.read_csv("sample_data.csv")
    
    # Preprocess the data
    processed_data = preprocess_data(data)
    
    # Separate features and targets
    X = processed_data.drop(['id', 'output'], axis=1)
    y = processed_data['output']
    
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Initialize and train the model
    model = DynamicFeatureSelector()
    model.fit(X_train, y_train)
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy}")
    print(f"Selected features: {model.selected_features}")
