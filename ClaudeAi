import pandas as pd
import numpy as np
import itertools
from sklearn.preprocessing import PolynomialFeatures

class FeatureEngineer:
    """
    Generates candidate features from input columns to help discover
    transformation rules when output dataset has more columns than input.
    """
    
    def __init__(self, input_df, output_df):
        """
        Initialize the FeatureEngineer.
        
        Args:
            input_df (pd.DataFrame): Input dataset with N columns
            output_df (pd.DataFrame): Output dataset with M columns
        """
        self.input_df = input_df
        self.output_df = output_df
        
        # List of operations to try for feature generation
        self.operations = [
            self._addition,
            self._subtraction,
            self._multiplication,
            self._division,
            self._squared,
            self._square_root,
            self._log,
            self._exp
        ]
    
    def generate_candidate_features(self):
        """
        Generate candidate features based on input columns.
        
        Returns:
            pd.DataFrame: Enhanced input DataFrame with additional generated features
        """
        print("Generating candidate features...")
        enhanced_df = self.input_df.copy()
        
        # Separate numerical and categorical columns
        numeric_cols = self.input_df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = self.input_df.select_dtypes(exclude=['number']).columns.tolist()
        
        # Step 1: Generate single-column transformations
        for col in numeric_cols:
            for operation in self.operations:
                try:
                    # Apply transformation and generate new feature name
                    op_name = operation.__name__.replace('_', '')
                    new_col_name = f"{op_name}_{col}"
                    
                    # Skip if column already exists
                    if new_col_name in enhanced_df.columns:
                        continue
                    
                    # Calculate transformed values
                    transformed_values = operation(self.input_df[col].values)
                    
                    # Check if the transformation produces valid results
                    if not np.any(np.isnan(transformed_values)) and not np.any(np.isinf(transformed_values)):
                        enhanced_df[new_col_name] = transformed_values
                        print(f"  Generated feature: {new_col_name}")
                except Exception as e:
                    print(f"  Error generating {operation.__name__} for {col}: {e}")
        
        # Step 2: Generate pairwise combinations of columns
        if len(numeric_cols) >= 2:
            for col1, col2 in itertools.combinations(numeric_cols, 2):
                for operation in [self._addition, self._subtraction, self._multiplication, self._division]:
                    try:
                        # Generate feature name
                        op_symbol = self._get_operation_symbol(operation)
                        new_col_name = f"{col1}{op_symbol}{col2}"
                        
                        # Skip if column already exists
                        if new_col_name in enhanced_df.columns:
                            continue
                        
                        # Calculate combined values
                        combined_values = operation(
                            self.input_df[col1].values, 
                            self.input_df[col2].values
                        )
                        
                        # Check if the combination produces valid results
                        if not np.any(np.isnan(combined_values)) and not np.any(np.isinf(combined_values)):
                            enhanced_df[new_col_name] = combined_values
                            print(f"  Generated feature: {new_col_name}")
                    except Exception as e:
                        op_name = operation.__name__.replace('_', '')
                        print(f"  Error generating {op_name} for {col1} and {col2}: {e}")
        
        # Step 3: Generate polynomial features (degree 2)
        if len(numeric_cols) >= 1:
            try:
                poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
                numeric_df = self.input_df[numeric_cols]
                poly_features = poly.fit_transform(numeric_df)
                
                # Skip the first n features as they are the original features
                poly_feature_names = []
                
                # Get the feature names from the transformer
                for i, feature_name in enumerate(poly.get_feature_names_out(numeric_cols)):
                    # Skip original features
                    if i >= len(numeric_cols):
                        poly_feature_names.append(feature_name.replace(' ', ''))
                
                # Add polynomial features to enhanced DataFrame
                for i, feature_name in enumerate(poly_feature_names):
                    # The +len(numeric_cols) is to skip the original features in poly_features
                    feature_values = poly_features[:, i + len(numeric_cols)]
                    
                    # Check if the column already exists
                    if feature_name in enhanced_df.columns:
                        continue
                    
                    # Check if the values are valid
                    if not np.any(np.isnan(feature_values)) and not np.any(np.isinf(feature_values)):
                        enhanced_df[feature_name] = feature_values
                        print(f"  Generated polynomial feature: {feature_name}")
            except Exception as e:
                print(f"  Error generating polynomial features: {e}")
        
        # Step 4: Generate categorical interactions if there are categorical columns
        if categorical_cols:
            # One-hot encode categorical columns if needed
            for cat_col in categorical_cols:
                dummies = pd.get_dummies(self.input_df[cat_col], prefix=cat_col)
                
                # Multiply numerical columns by each dummy variable
                for num_col in numeric_cols:
                    for dummy_col in dummies.columns:
                        new_col_name = f"{num_col}_by_{dummy_col}"
                        
                        # Skip if column already exists
                        if new_col_name in enhanced_df.columns:
                            continue
                        
                        enhanced_df[new_col_name] = self.input_df[num_col] * dummies[dummy_col]
                        print(f"  Generated categorical interaction: {new_col_name}")
        
        # Step 5: Find if output columns are highly correlated with any of the generated features
        # This helps identify potential transformations
        self._evaluate_candidate_features(enhanced_df)
        
        print(f"Generated {len(enhanced_df.columns) - len(self.input_df.columns)} new features")
        return enhanced_df
    
    def _evaluate_candidate_features(self, enhanced_df):
        """
        Evaluate generated features by checking correlation with output columns.
        
        Args:
            enhanced_df (pd.DataFrame): Enhanced input DataFrame with generated features
        """
        # Only analyze numeric columns
        numeric_enhanced = enhanced_df.select_dtypes(include=['number'])
        numeric_output = self.output_df.select_dtypes(include=['number'])
        
        if numeric_output.empty:
            return
        
        # Find correlations between generated features and output columns
        print("\nTop correlations between generated features and output columns:")
        
        for output_col in numeric_output.columns:
            correlations = {}
            
            for feature_col in numeric_enhanced.columns:
                if feature_col in self.input_df.columns:
                    continue  # Skip original features
                
                try:
                    # Calculate correlation
                    corr = numeric_enhanced[feature_col].corr(numeric_output[output_col])
                    
                    if not np.isnan(corr):
                        correlations[feature_col] = abs(corr)  # Use absolute correlation
                except:
                    continue
            
            # Sort by correlation (highest first)
            sorted_corrs = sorted(correlations.items(), key=lambda x: x[1], reverse=True)
            
            # Print top 3 correlations
            if sorted_corrs:
                print(f"\nFor {output_col}:")
                for feature, corr in sorted_corrs[:3]:
                    print(f"  {feature}: correlation = {corr:.4f}")
    
    # Helper operations
    def _addition(self, a, b=None):
        if b is not None:
            return a + b
        return a  # Placeholder for unary version
    
    def _subtraction(self, a, b=None):
        if b is not None:
            return a - b
        return -a
    
    def _multiplication(self, a, b=None):
        if b is not None:
            return a * b
        return a
    
    def _division(self, a, b=None):
        if b is not None:
            return np.divide(a, b, out=np.zeros_like(a), where=b!=0)
        return np.divide(1, a, out=np.zeros_like(a), where=a!=0)
    
    def _squared(self, a):
        return a * a
    
    def _square_root(self, a):
        return np.sqrt(np.abs(a))  # Using abs to avoid complex numbers
    
    def _log(self, a):
        return np.log(np.abs(a) + 1e-10)  # Adding small constant to avoid log(0)
    
    def _exp(self, a):
        return np.exp(a)
    
    def _get_operation_symbol(self, operation):
        """Get symbol representation of operation for column naming"""
        if operation == self._addition:
            return "+"
        elif operation == self._subtraction:
            return "-"
        elif operation == self._multiplication:
            return "*"
        elif operation == self._division:
            return "/"
        return "_"
