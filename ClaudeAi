import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

class RuleValidator:
    """
    Validates discovered transformation rules by applying them to test data
    and comparing the results with actual output values.
    """
    
    def validate_rules(self, all_rules, input_df, output_df, categorical_handler, test_size=0.2, random_state=42):
        """
        Validate discovered rules on test data.
        
        Args:
            all_rules (dict): Dictionary of discovered rules by output column and segment
            input_df (pd.DataFrame): Input dataset
            output_df (pd.DataFrame): Output dataset
            categorical_handler (CategoricalHandler): Handler for categorical data
            test_size (float): Proportion of data to use for testing
            random_state (int): Random seed for reproducibility
            
        Returns:
            float: Overall validation accuracy
        """
        # Split data into train and test sets
        input_train, input_test, output_train, output_test = train_test_split(
            input_df, output_df, test_size=test_size, random_state=random_state
        )
        
        # Apply rules to test data
        predicted_output = self._apply_rules(all_rules, input_test, categorical_handler)
        
        # Calculate accuracy per output column
        column_accuracies = {}
        for col in output_test.columns:
            if col in predicted_output.columns:
                # Calculate normalized RMSE
                rmse = np.sqrt(np.mean((predicted_output[col] - output_test[col]) ** 2))
                
                # Normalize by the range of the output
                output_range = output_test[col].max() - output_test[col].min()
                if output_range > 0:
                    normalized_rmse = rmse / output_range
                    accuracy = max(0, 1 - normalized_rmse)
                else:
                    # If range is 0, check if predictions match exactly
                    accuracy = float(np.array_equal(predicted_output[col], output_test[col]))
                
                column_accuracies[col] = accuracy
        
        # Calculate overall accuracy
        if column_accuracies:
            overall_accuracy = sum(column_accuracies.values()) / len(column_accuracies)
        else:
            overall_accuracy = 0.0
            
        # Print detailed accuracy report
        print("\nValidation Results:")
        print(f"{'Column':<15} {'Accuracy':<10}")
        print("-" * 25)
        for col, acc in column_accuracies.items():
            print(f"{col:<15} {acc:.4f}")
            
        return overall_accuracy
    
    def _apply_rules(self, all_rules, input_df, categorical_handler):
        """
        Apply discovered rules to input data to predict outputs.
        
        Args:
            all_rules (dict): Dictionary of discovered rules by output column and segment
            input_df (pd.DataFrame): Input dataset
            categorical_handler (CategoricalHandler): Handler for categorical data
            
        Returns:
            pd.DataFrame: Predicted output dataset
        """
        # Initialize empty DataFrame for predictions
        predicted_output = pd.DataFrame(index=input_df.index)
        
        # Segment the input data
        segments = categorical_handler.segment_data(input_df)
        
        # Apply rules to each segment
        for output_col, rules_by_segment in all_rules.items():
            # Initialize column with NaN values
            predicted_output[output_col] = np.nan
            
            # Apply segment-specific rules
            for segment_name, rule in rules_by_segment.items():
                if segment_name in segments:
                    segment_df = segments[segment_name]
                    segment_indices = segment_df.index
                    
                    try:
                        predicted_values = self._evaluate_rule(rule, segment_df)
                        predicted_output.loc[segment_indices, output_col] = predicted_values
                    except Exception as e:
                        print(f"Error applying rule '{rule}' for {output_col} in segment {segment_name}: {e}")
        
        return predicted_output
    
    def _evaluate_rule(self, rule, input_df):
        """
        Evaluate a rule string on the input data.
        
        Args:
            rule (str): Rule string to evaluate
            input_df (pd.DataFrame): Input dataframe
            
        Returns:
            np.ndarray: Predicted values
        """
        # Handle different rule types
        if "Unknown transformation" in rule:
            # Return NaN for unknown rules
            return np.full(len(input_df), np.nan)
            
        if "Decision tree" in rule:
            # For decision tree rules, we can't directly evaluate
            # In a real implementation, you would store the trained model
            return np.full(len(input_df), np.nan)
        
        # For simple arithmetic rules
        try:
            # Replace column names with actual values
            numeric_input_df = input_df.copy()
            if isinstance(numeric_input_df, pd.Series):
                numeric_input_df = pd.DataFrame(numeric_input_df)
            
            # Create a dictionary mapping column names to their values
            columns_dict = {}
            for col in numeric_input_df.columns:
                if col in rule:
                    columns_dict[col] = numeric_input_df[col].values
            
            # Simple parsing and evaluation for basic arithmetic
            # This is a simplified implementation - a real one would use a proper expression parser
            result = self._simple_rule_evaluation(rule, columns_dict)
            return result
            
        except Exception as e:
            print(f"Error evaluating rule '{rule}': {e}")
            return np.full(len(input_df), np.nan)
    
    def _simple_rule_evaluation(self, rule, columns_dict):
        """
        Simple evaluation of arithmetic rules.
        
        Args:
            rule (str): Rule string to evaluate
            columns_dict (dict): Dictionary mapping column names to their values
            
        Returns:
            np.ndarray: Result of rule evaluation
        """
        # This is a simplified implementation - in practice, you'd use a proper expression parser
        # Handle some common cases
        
        # Direct column reference
        if rule in columns_dict:
            return columns_dict[rule]
        
        # Constant multiplication: "2 * col"
        if '*' in rule and len(rule.split('*')) == 2:
            parts = rule.split('*')
            factor_part = parts[0].strip()
            col_part = parts[1].strip()
            
            if col_part in columns_dict:
                try:
                    factor = float(factor_part)
                    return factor * columns_dict[col_part]
                except:
                    pass
            
            if factor_part in columns_dict:
                try:
                    factor = float(col_part)
                    return factor * columns_dict[factor_part]
                except:
                    pass
                    
            if factor_part in columns_dict and col_part in columns_dict:
                return columns_dict[factor_part] * columns_dict[col_part]
        
        # Addition: "col1 + col2" or "col + constant"
        if '+' in rule and len(rule.split('+')) == 2:
            parts = rule.
